# Big-Transfer

Tasks / Rubric (100 points)

Write a 2 page (excluding pictures) summary of what transfer learning (10 points)
Write a 2 page (excluding pictures) summary of what architectural improvements, if any, the authors have assumed on top the ResNet-xyz V1 architecture and why (20 points)
Write a 4 page (excluding figures) summary of the key points that need to be made so a non-expert can understand the differences between GN, WS and BN. The top 3 comparisons will make it to my class notes with attribution. (30 points)
Write a 2 page (excluding figures) summary of MixUp regularization and how this may help (30 points).
Explain all models that are used in producing performance results (eg RetinaNet) (10 points)


# What is Transfer Learning?
Transfer learning is a method in Machine Learning where a model made for a task is reused as the starting point for a model on a second task.

It is a popular approach in deep learning where pre-trained models are used as the starting point on computer vision and natural language processing tasks given the vast compute and time resources required to develop neural networks on these problems and from the huge jumps in skill that they provide on related problems.

Example: A visual task
In a visual task, the input is an image.
It could be a classifier where there is a image of a lung and you have to point out if there is any abnormality in it.

